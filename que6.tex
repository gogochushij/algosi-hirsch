\section{(6) Set Cover~-- ii (Осипов Д.)}
\subsection{Жадный приближенный алгоритм}
Условие задачи все еще \hyperlink{setcover}{\texttt{в том билете}}.

Сейчас окажется, что обычный жадный подход часто дает результат лучше, чем все подходы к Set Cover, описанные до этого. Именно, если обозначить $H_n = 1 + \frac{1}{2} + \cdots + \frac{1}{n}$, то получим:

\begin{algodescription}{Приближенное $H_n$-оптимальное решение}

Вот вполне интуитивный <<жадник>>:

\begin{algorithm}[H]
	\DontPrintSemicolon
	\SetKwFor{For}{for}{:}{}
	\SetKwFor{While}{while}{:}{}
	\SetKwProg{Fn}{}{:}{}
	\SetKwFunction{Greedy}{Greedy}
	\SetKwFunction{append}{append}
	\Fn{\Greedy{$E=[e_1,\ldots,e_n]$,$S=[S_1,\ldots,S_m]$,$w=[w_1,\ldots,w_m]$}}{
		$I=[]$\;
		$\hat{S}_1,\ldots,\hat{S}_m=S_1,\ldots,S_m$\;
		\While{$\bigcup I \neq  E$}{
			$l=$ любой индекс $j$ т.ч. $\hat{S}_j \neq \varnothing$ и $\frac{w_j}{|\hat{S}_j|}$ минимально\;
			Добавить $l$ в $I$\;
			\For{$j=1\ldots m$}{
				$\hat{S}_j = \hat{S}_j\smallsetminus S_l$\;
			}
		}
	}
\end{algorithm}
$ $
\end{algodescription}

Ясно, что этот алгоритм действительно дает покрытие всего $E$. Нужно доказать точность.

\begin{theorem*} 
    Приведенный алгоритм $H_n$-оптимальный, где $H_n = 1 + \frac{1}{2} + \ldots + \frac{1}{n}$.
\end{theorem*}
\begin{proof}
    Пусть алгоритм сделал $l$ итераций. За $n_k$ обозначим количество непокрытых элементов $E$ перед $k$-той итерацией (полагаем по определению $n_{l+1}=0$). Так, $n = n_1 > \ldots > n_{l+1} = 0$.

    \textbf{Пока поверим}, что если на $k$-той итерации выбрано множество $S_i$, то справедливо неравенство:
    
    $$w_i \leq \frac{n_k - n_{k+1}}{n_k}OPT$$
    
    По модулю этого факта доказываем $H_n$-оптимальность. Пусть $I$~-- множество индексов, найденное жадным алгоритмом. Тогда суммарный вес всех выбранных множеств оценивается как:
    
    $$\sum_{j\in I}w_j \leq \sum_{k=1}^l\frac{n_k-n_{k+1}}{n_k} OPT$$
    $$ = OPT\cdot\sum_{k=1}^l\left(\underbrace{\frac{1}{n_k} + \cdots + \frac{1}{n_k}}_{n_k-n_{k+1}\text{ раз}}\right)$$
    $$ \leq OPT \cdot\sum_{k=1}^l\left(\frac{1}{n_k} + \frac{1}{n_k - 1} + \cdots + \frac{1}{n_{k+1}+1}\right)$$
    $$ = OPT\cdot\sum_{k=1}^n\frac{1}{k} = OPT\cdot H_n$$
    Это и требовалось. Теперь доказываем неравенство $w_i \leq \frac{n_k - n_{k+1}}{n_k}OPT$.
    
    Для данной итерации $k$ и выбранного на ней элемента $S_i$ обозначим $I_k$~-- множество индексов, выбранных на итерациях $1, \ldots, k-1$, а для всякого $j=1\ldots m$ положим $\hat{S}_j = S_j \setminus \bigcup_{p \in I_k}S_p$~-- множество элементов из $S_j$, которые были покрыты на $k$-той итерации. Заметьте, что получается ровно те $\hat{S}_j$, которые фигурируют в псевдокоде. По смыслу алгоритма получается $$\frac{w_i}{|\hat{S}_i|} = \min_{j:\, \hat{S}_j\neq\varnothing} \frac{w_j}{|\hat{S}_j|}.$$
    Обозначим за $O$ множество индексов в оптимальном решении (т.е. соответствующее суммарному весу $OPT$). Ясно, что $j \in O \implies \hat{S}_j \neq\varnothing$, так что: $$\min_{j:\, \hat{S}_j\neq\varnothing} \frac{w_j}{|\hat{S}_j|} \leq \min_{j \in O} \frac{w_j}{|\hat{S}_j|}$$
    
    Вспомним такое неравенство из курса анализа. \textit{Пусть $a_1, \ldots, a_q, b_1, \ldots, b_q$~-- положительные числа. Тогда}
    $$\min_{j=1\ldots q} \frac{a_j}{b_j} \leq \frac{\sum\limits_{j=1\ldots q} a_j}{\sum\limits_{j=1\ldots q} b_j} \leq \max_{j=1\ldots q} \frac{a_j}{b_j}$$
    
    Применим его первую часть для чисел $w_j, |\hat{S}_j|$, где $j \in O$, получим:
    $$\min_{j\in O} \frac{w_j}{\left|\hat{S}_j\right|} \leq \frac{\sum\limits_{j \in O} w_j}{\sum\limits_{j \in O} |\hat{S}_j|}$$
    Числитель просто равен $OPT$ по определению, а знаменатель не меньше $n_k = |\bigcup_{j \in O} \hat{S}_j|$ (это просто количество оставшихся непокрытых элементов!). Резюмируя, имеем: $$\frac{w_i}{|\hat{S}_i|} \leq \frac{OPT}{n_k}$$
    А так как на $k$-той итерации покрываем $|\hat{S}_i| = n_k - n_{k+1}$, получаем наконец:
    $$w_i \leq \frac{|\hat{S}_i|\cdot OPT}{n_k} = \frac{(n_k-n_{k+1})\cdot OPT}{n_k}$$

\end{proof}
