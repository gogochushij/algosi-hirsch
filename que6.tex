\section{Set Cover -- ii}
\subsection{Жадный приближенный алгоритм}
Условие задачи все еще \hyperlink{setcover}{\texttt{в том билете}}.

Сейчас окажется, что обычный жадный подход часто дает результат лучше, чем все подходы к Set Cover, описанные до этого. Именно, если обозначить $H_n = 1 + \frac{1}{2} + ... + \frac{1}{n}$, то получим:

\statement{Приближенное $H_n$-оптимальное решение.}{}

Вот вполне интуитивный <<жадник>>:

\begin{lstlisting}[escapeinside=``]
function Greedy (`$E = [e_1, ..., e_n]$`, `$S = [S_1, ..., S_m]$`, `$w = [w_1, ..., w_m]$`):
I = []
`$\hat{S_1}, ... , \hat{S_m}$` `$= S_1, ..., S_m$`
while I is not a set cover:
    `$l$` `$=$` any index j such that `$\hat{S_j} \neq \emptyset $` and `$\frac{w_j}{|\hat{S_j}|}$` is minimal
    I.append(`$l$`)
    for `$j$`=1..m:
        `$\hat{S_j} = \hat{S_j}\setminus S_l$`
\end{lstlisting}

Ясно, что этот алгоритм действительно дает покрытие всего $E$. Нужно доказать точность.

\underline{Доказываем $H_n$-оптимальность.} Пусть алгоритм сделал $l$ итераций. За $n_k$ обозначим количество непокрытых элементов $E$ перед $k$-той итерацией (полагаем по определению $n_{l+1}=0$). Так, $n = n_1 > ... > n_{l+1} = 0$. 

\textbf{Пока поверим}, что если на $k$-той итерации выбрано множество $S_i$, то справедливо неравенство:

$$w_i \leq \frac{n_k - n_{k+1}}{n_k}OPT$$

По модулю этого факта доказываем $H_n$-оптимальность. Пусть $I$ -- множество индексов, найденное жадным алгоритмом. Тогда суммарный вес всех выбранных множеств оценивается как:

$$\summ{j\in I}w_j \leq \summ[l]{k=1}\frac{n_k-n_{k+1}}{n_k} OPT$$ 
$$ = OPT\cdot\summ[l]{k=1}(\underbrace{\frac{1}{n_k} + ... + \frac{1}{n_k}}_{n_k-n_{k+1}\text{ раз}})$$
$$ \leq OPT \cdot\summ[l]{k=1} (\frac{1}{n_k} + \frac{1}{n_k - 1} + ... + \frac{1}{n_{k+1}+1})$$ 
$$ = OPT\cdot\summ[n]{k=1}\frac{1}{k} = OPT\cdot H_n$$
Это и требовалось. Теперь доказываем неравенство $w_i \leq \frac{n_k - n_{k+1}}{n_k}OPT$.

Для данной итерации $k$ и выбранного на ней элемента $S_i$ обозначим $I_k$ -- множество индексов, выбранных на итерациях $1, ..., k-1$, а для всякого $j=1...m$ положим $\hat{S_j} = S_j \setminus \bigcup_{p \in I_k}S_p$ -- множество элементов из $S_j$, которые были покрыты на $k$-той итерации. Заметьте, что получается ровно те $\hat{S_j}$, которые фигурируют в псевдокоде. По смыслу алгоритма получается $$\frac{w_i}{|\hat{S_i}|} = \minn{j:\, \hat{S_j}\neq \emptyset} \frac{w_j}{|\hat{S_j}|}.$$
Обозначим за $O$ множество индексов в оптимальном решении (т.е. соответствующее суммарному весу $OPT$). Ясно, что $j \in O \implies \hat{S_j} \neq \emptyset$, так что: $$\minn{j:\, \hat{S_j}\neq \emptyset} \frac{w_j}{|\hat{S_j}|} \leq \minn{j \in O} \frac{w_j}{|\hat{S_j}|}$$

Вспомним такое неравенство из курса анализа. \textit{Пусть $a_1, ..., a_q, b_1, ..., b_q$ -- положительные числа. Тогда}
$$\minn{j=1..q} \frac{a_j}{b_j} \leq \frac{\summ{j=1..q} a_j}{\summ{j=1..q} b_j} \leq \maxx{j=1..q} \frac{a_j}{b_j}$$

Применим его первую часть для чисел $w_j, |\hat{S_j}|$, где $j \in O$, получим:
$$\minn{j\in O} \frac{w_j}{|\hat{S_j}|} \leq \frac{\summ{j \in O} w_j}{\summ{j \in O} |\hat{S_j}|}$$
Числитель просто равен $OPT$ по определению, а знаменатель не меньше $n_k = |\bigcup_{j \in O} \hat{S_j}|$ (это просто количество оставшихся непокрытых элементов!). Резюмируя, имеем: $$\frac{w_i}{|\hat{S_i}|} \leq \frac{OPT}{n_k}$$
А так как на $k$-той итерации покрываем $|\hat{S_i}| = n_k - n_{k+1}$, получаем наконец:
$$w_i \leq \frac{|\hat{S_i}|\cdot OPT}{n_k} = \frac{(n_k-n_{k+1})\cdot OPT}{n_k}\;\blacksquare$$