\section{(17) Хеш-таблицы. Универсальные семейства хеш-функций. (Осипов Д.)}

\begin{problem*}
	Реализовать структуру~-- множество, поддерживающее операции вставки (Insert), удаления (Delete), поиска (Search).
\end{problem*}
\subsection{Прямая адресация}
Считаем, что элементы нашего множества~-- целые числа в диапазоне $[0, m-1]$.

\statement{Решение (очевидное~-- прямая адресация): }{всегда на всё O(1) времени, O(m) памяти.} Заводим булевый массив A из $m$ нулей.
\begin{itemize}
    \item Вставить $k$~-- пометить A[$k$] = 1,
    \item Удалить $k$~-- пометить A[$k$] = 0,
    \item Найти $k$~-- посмотреть A[$k$].
\end{itemize}\qed

\subsection{Хеш-таблица с чеинингом}
Если так случилось, что элементами множества могут быть не все числа $\{0, \ldots, m-1\}$, а лишь элементы некоторого $K \subseteq \{0, \ldots, m-1\}$, $|K| = n$, то при большом $m$ и маленьком $n$ будет бесполезно потрачено много памяти.

Пусть теперь $K$~-- произвольное множество натуральных чисел, $m$~-- натуральный параметр.

\statement{Решение (хеш-таблица с чеинингом).}{}

Предположим, что выбрана некоторая \textit{хеш-функция} $$h: K \rightarrow \{0, \ldots, m-1\},$$ вычислимая за $O(1)$. Наше множество будем хранить в массиве \underline{двусторонних списков} $T[0\ldots m-1]$. Операции реализуем так:
\begin{itemize}
    \item Вставить $k$~-- положить $k$ в начало списка $T[h(k)]$.
    \item Найти $k$~-- просмотреть весь список $T[h(k)]$.
    \item Удалить $k$~-- найти $k$ в списке $T[h(k)]$ и удалить его, если нашелся.
\end{itemize}

Описание алгоритма закончено.

\subsection{\heart~Гипотеза простого равномерного хеширования: оценки (кажется, не входит в экз?????)}

Для работоспособности алгоритма функция $h$ может быть совершенно любой, но желательно, чтобы хеш-коды $\{h(k)\}_{k\in K}$ распределялись равномерно. Для этого предположим, что:
\begin{enumerate}
    \item для каждого $k \in K$ значение $h(k)$ является случайной величиной,
    \item $\mathbb P\{h(k) = r\} = \frac{1}{m}$ для всех $r \in \{0, \ldots, m-1\}$,
    \item для всех $k_1 \neq k_2$ величины $h(k_1)$ и $h(k_2)$ независимы.
\end{enumerate}
Эти предположения составляют \textit{гипотезу простого равномерного хеширования}.

Сейчас мы покажем, что в этой модели \underline{операция поиска выполняется за $O\left(\frac{n}{m}+1\right)$.}\footnote{Стоит понимать как O(1) в случае $\frac{n}{m} \leq 1$ и $O\left(\frac{n}{m}\right)$ иначе.}

\begin{theorem*}
	При гипотезе простого равномерного хеширования средняя длина списка есть $\frac{n}{m}$.
\end{theorem*}
\begin{proof}
Занумеруем $K = \{k_1, \ldots, k_n\}$. Фиксируем $j \in \{0, \ldots, m-1\}$. Для $i=1\ldots n$ определим случайную величину
$$X_{ij} = [h(k_i)=j] \text{~-- попал ли элемент $k_i$ в ячейку $j$.}$$
Из пункта 2) ясно, что $\mathbb E X_{ij} = \frac{1}{m}$. Также ясно, что длина списка $T[j]$ есть $X_{1j}+\ldots+X_{nj}$. Матожидание этой величины есть $$\mathbb E \sum_{i=1}^n X_{ij} = \sum_{i=1}^n \mathbb E X_{ij} = \frac{n}{m}.$$
\end{proof}

Далее нужно рассмотреть два случая: искомый элемент $k_i$ есть в списке $T[h(k_i)]$ \textit{(успешный поиск)}, либо же его нет \textit{(неудачный поиск)}.

\begin{theorem*}
	Среднее время работы неудачного поиска есть $O\left(\frac{n}{m}+1\right)$
\end{theorem*}
\begin{proof}
В случае, если элемента $k$ в списке $T[h(k)]$ нет, то алгоритм просматривает весь список длины $\frac{n}{m}$.
\end{proof}

\begin{theorem*}
	Среднее время работы успешного поиска есть $O\left(\frac{n}{m}+1\right)$.
\end{theorem*}
\begin{proof}
Тут придется повозиться. Предположим, что $k_1, \ldots, k_n$ занумерованы в порядке добавления их в множество. Фиксируем $k_i$ и считаем среднее время поиска его в списке $T[h(k_i)]$. Для $j=1\ldots m$ определим случайную величину $$X_{ij} = [h(k_i) = h(k_j)] \text{~-- <<$k_i$ в одном списке с $k_j$>>.}$$ Ясно, что $\mathbb E X_{ii} = 1$ и $\mathbb E X_{ij} = \frac{1}{m}$ при $j\neq i$.

Алгоритм ищет $k_i$ в списке $T[h(k_i)]$. Сколько элементов он пройдет, прежде чем наткнется на $k_i$? Он пройдет те элементы $k_j$, которые лежат в $T[h(k_i)]$ (т.е. $h(k_i)=h(k_j)$) и которые находятся в этом списке раньше $k_i$ (т.е. $j\geq i$~-- ведь каждый новый элемент добавляется в начало списка). Поэтому количество пройденных элементов равно $$X_{in} + \ldots + X_{ii}.$$

Матожидание времени поиска фиксированного $k_i$ равно $$\mathbb E \sum_{j=i}^n X_{ij} = \mathbb E X_{ii} + \sum_{j=i+1}^n \mathbb E X_{ij} = 1 + \frac{n-i}{m}$$

А если взять среднее по $i=1\ldots n$, получаем: $$\frac{1}{n} \sum_{i=1}^n\left(1+\frac{n-i}{m}\right) = 1 + \frac{n-1}{2m} = O\left(\frac{n}{m} + 1\right)$$
\end{proof}

\subsection{Универсальное семейство хеш-функций: оценки}

\begin{definition*}
	Универсальное семейство хеш-функций $\mathcal{H}$~-- такое множество хеш-функций, что для любой пары различных ключей $k_1$, $k_2$ количество функций $h \in \mathcal{H}$ таких, что $h(k_1) = h(k_2)$, не превосходит $\frac{|\mathcal{H}|}{m}$.
\end{definition*}

\statement{NB: }{} Другими словами, при случайном равновероятном выборе функции из $\mathcal{H}$ вероятность того, что для фиксированной пары различных ключей $k_1, k_2$ случится коллизия $h(k_1) = h(k_2)$, не превосходит $\frac{1}{m}$.

Если у нас есть такое семейство, то перед началом работы мы выбираем из него случайно и равномерно одну функцию, по ней строим хеш-таблицу с чеинингом.

Оказывается, что в этой модели среднее время поиска остается тем же самым.

\begin{theorem*}
	В модели универсального хеширования среднее время работы как неудачного, так и успешного поиска есть $O\left(\frac{n}{m}+1\right)$.
\end{theorem*}
\begin{proof}
Для элементов $k$ и $l$ обозначим:
$$X_{kl} = [h(k) = h(l)]$$
Длина цепочки $T[h(l)]$, в которой, возможно, лежит $l$, есть $X_{k_1\, l} + \ldots + X_{k_n\ l}$.

Если $l$ не лежит в этой цепочке, то матожидание этой суммы не превосходит $\frac{n}{m}$, так как матожидание каждого слагаемого не превосходит $\frac{1}{m}$ (см. \textit{\textbf{NB}} выше).

Если же $l$ лежит в этой цепочке, то матожидание суммы не превосходит $1 + \frac{n-1}{m}$: матожидание слагаемого $X_{ll}$ равно 1, матожидание любого другого слагаемого $\leq \frac{1}{m}$.

Получается, что и в том, и в другом случае число шагов оценивается сверху как $O\left(\frac{n}{m}+1\right)$.
\end{proof}

\subsection{Универсальное семейство хеш-функций: построение}
Осталось построить какое-нибудь универсальное семейство хеш-функций. Это несложно. Опишем для числового множества.

Выберем простое $p > m$. Для всяких целых $a \in \{1, \ldots, p-1\}$ и $b \in \{0, \ldots, p-1\}$ положим $$h_{ab}(k) = ((ak+b)\mod p) \mod m$$
\begin{theorem*}
	$\mathcal{H} = \{h_{ab}\}$  универсально.
\end{theorem*}
\begin{proof}
Доказательство счётом. Убедитесь самостоятельно в следующем:
\begin{enumerate}
\item Фиксируем различные $k_1, k_2 \in \{0, \ldots, m-1\}$. Обозначим $t_i = (ak_i + b)\mod p$ для $i = 1,2$. Докажите, что $t_1 \neq t_2$. Напоминание: $a\neq 0$ и $k_1, k_2 < m < p$.

\item Фиксируем различные $k_1, k_2 \in \{0, \ldots, m-1\}$ и различные $t_1, t_2 \in \{0, \ldots, p-1\}$. Докажите, что существуют и единственные $a \in \{1, \ldots, p-1\}, b \in \{0, \ldots, p-1\}$, что $t_i = (ak_i+b)\mod p$ для $i=1,2$ (вычислите эти $t_1, t_2$).

Следовательно, каждая пара $(t_1, t_2)$, где $t_1 \neq t_2$, при фиксированных $k_1 \neq k_2$ реализуема ровно одним способом. Так что если выбирать хеш-функцию $h_{ab}$ случайно и равновероятно из $\mathcal{H}$, то для нее пара $(t_1, t_2)$ окажется так же равновероятна среди всех пар $\{(t_1, t_2) \colon t_1 \neq t_2\}$.

Теперь вероятность того, что $h_{ab}(k_1) = h_{ab}(k_2)$, равна вероятности, с которой различные равновероятно выбранные $t_1, t_2 \in \{0, \ldots, p-1\}$ совпадут по модулю $m$.

\item Докажите, что для фиксированного $t_1 \in \{0, \ldots, p-1\}$ количество таких $t_2 \in \{0, \ldots, p-1\}$, что $t_1 \neq t_2$ и $t_1 \equiv t_2(\text{mod }m)$, не превосходит $\frac{p-1}{m}$.

Тогда при фиксированном $t_1$ вероятность выбрать $t_2 \neq t_1$ т.ч. $t_1\equiv t_2 (\text{mod }m)$ не превосходит $$\frac{1}{p-1} \cdot \frac{p-1}{m} = \frac{1}{m}$$

Нетрудно видеть, что эта оценка сверху справедлива и для успешного равновероятного выбора пары $(t_1, t_2)$.
\end{enumerate}
\end{proof}



