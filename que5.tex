\hypertarget{setcover}{\section{Set Cover - i}}

\statement{Задача (о покрытии множествами, Set Cover).}{Пусть дано множество $\{e_1, ..., e_n\} = E$ и несколько подмножеств $S_1, ..., S_m \subseteq E$, каждому $S_j$ присвоен неотрицательный вес $w_j$. Необходимо выбрать из $S_1, ..., S_m$ набор, полностью покрывающий $E$, с минимальным суммарным весом. Более формально: требуется найти такое $I \subseteq \{1, ..., m\}$, что: $$\bigcup_{j\in I} = E \text{ и } \sum_{j \in I} S_j \text{ минимально.}$$}

В этом билете представляются различные подходы к приближенным решениям этой задачи. 

\subsection{Сведение к задаче линейного программирования}

\statement{Определение.}{Задача линейного программирования} -- задача минимизации (максимизации) некоторой линейной функции $h = h(x_1, ..., x_n)$ при ограничениях вида $g_k \land b_k$, где $\land$ есть один из знаков $\leq, \geq$, а $g_k = g_k(x_1, ..., x_n)$ -- линейные функции; $b_k$ -- числа. Функция $h$ называется \textit{целевой} функцией.

Далее в тексте сокращение \textit{ЛП-задача} будет означать \textit{задача линейного программирования}.

Обозначим за $f_j$ количество множеств среди $S_1, ..., S_m$, в которые входит элемент $e_j$. Положим $f = \maxx{i=1..n} f_j$. Оказывается, что эти параметры играют решающую роль в следующем решении.

Переформулируем задачу Set Cover. Каждому множеству $S_j$ сопоставим переменную $x_j$, принимающую значение 1, если $S_j$ взято в набор $I$, и 0 -- иначе. Столбец $x = (x_1, ..., x_m)^T$ взаимно однозначно кодирует любой набор индексов $I$. Тогда целевая функция -- суммарный вес покрытия -- выглядит как $\summ[m]{j=1} w_j x_j$. Ограничение на то, что набор $I$ -- покрытие, записывается так: каждый элемент $e_i$ покрыт хотя бы одним элементом $I$, или же что условие $\summ{j:\, e_i \in S_j} x_j \geq 1$ выполнено для всех $i=1..n$. Итак, формулировка задачи:

$$\summ[m]{j=1} w_j x_j \rightarrow \min,$$
$$\summ{j:\, e_i \in S_j} x_j \geq 1, \;\;\; i=1..n,$$
$$x_j \in \{0, 1\}, \;\;\; j=1..m$$

Это \underline{почти} ЛП-задача. Если бы умели решать такие задачи точно, решили бы и нашу -- это просто ее переформулировка. <<Ослабим>> задачу до настоящей ЛП-задачи:

$$\summ[m]{j=1} w_j x_j \rightarrow \min,$$
$$\summ{j:\, e_i \in S_j} x_j \geq 1, \;\;\; i=1..n,$$
$$x_j \geq 0 \;\;\; j=1..m$$

Мы перестали требовать, что $x_j$ обязательно должен быть целым и не превышать единицы. Отметим, что если обозначить минимум ЦФ в исходной задаче за $OPT$, а в ослабленной -- за $Z^*$, то будет справедлива оценка $$Z \leq OPT,$$ так как фактически вторая задача -- следствие первой.

\statement{Приближенное $f$-оптимальное решение (методом прямой ЛП-задачи, primal).}{}

\underline{Считаем, что ослабленную ЛП-задачу мы решать умеем.} Пусть $x^* = (x_1^*, ..., x_m^*)^T$ -- оптимальное решение ослабленной ЛП-задачи, т.е. $Z = \summ[m]{j=1} w_j x_j^*$. Сконструируем из нее решение исходной задачи (и задачи Set Cover) следующим образом:
$$x_j = 1\, (j \in I) \iff x_j^* \geq 1/f;$$

Итак, алгоритм заключается в следующем: мы находим минимум $x_j^*$ ослабленной ЛП-задачи, а далее в покрытие берем все $S_j$, для которых получилось $x_j^* \geq 1/f$. Теперь докажем его корректность и точность.

\underline{Найденный набор $S$-ок действительно покрывает всё $E$}. 

Именно, докажем, что каждый элемент $e_i \in E$ покрыт какой-то $S-$кой. Найденное решение $x^*$ удовлетворяет ослабленной ЛП-задаче, то есть для данного $e_i$ имеем $\summ{j: \, e_i \in S_j} x_j^* \geq 1$. В этой сумме по определению $f_i = \#\{j: \, e_i \in S_j\} \leq f$ членов, значит, хотя бы один из них $x_k^*\geq 1/f$. Значит, соответствующий $x_k = 1$, что доказывает то, что $e_i$ покрыт $S_k$. 

\underline{Теперь докажем $f$-оптимальность.} 

Обозначим (снова) минимальное значение целевой функции исходной почти-ЛП задачи за $OPT$, а ослабленной ЛП-задачи за $Z \leq OPT$.  (То есть, в обозначениях $x^*$ имеем $Z = \summ[m]{j=1} w_j x_j^*$). Для всякого $j\in I$ имеем $x_j^* \geq 1/f$, или же $x_j^*\cdot f \geq 1$. Тогда значение целевой функции в найденном решении исходной почти-ЛП задачи оценивается как:
$$\summ[m]{j=1} w_j x_j = \summ{j \in I} w_j \leq f \summ{j \in I} w_j x_j^* \leq f \summ[m]{j=1} w_j x_j^* = f Z^* \leq f \cdot OPT.$$ Таким образом, найденное решение хуже оптимального не более, чем в $f$ раз. $\blacksquare$


\subsection{Следствие для задачи вершинного покрытия (Vertex Cover)}
\statement{Задача (о вершинном покрытии, Vertex Cover).} {Пусть дан неориентированный граф $G = (V, E)$, каждой вершине $i$ которого сопоставлен неотрицательный вес $w_i$. Найти минимальный по весу набор вершин $C \subseteq V$ такой, что всякое ребро графа хотя бы одним из двух концов лежит в $C$.} 

\statement{Приближенное 2-оптимальное решение.}{} Это частный случай задачи Set Cover: основное множество -- множество ребер графа $E$, а каждой вершине $i \in V$ сопоставляется множество $S_i$ веса $w_i$, состоящее из ребер, смежных с $i$. Причем в обозначениях предыдущего раздела каждое ребро $(i, j)$ содержится ровно в двух множествах: $S_i, S_j$, поэтому $f = 2$, а значит, алгоритм становится 2-оптимальным. $\blacksquare$

\subsection{Двойственная задача}
\texttt{От автора: к сожалению, получился не очень приятный для чтения параграф. Автор не смог вникнуть в <<экономический смысл>> двойственной ЛП-задачи, поэтому все рассуждения построены на противной формалистике с матрицами и суммами. Возможно, вы лучше поймете эту тему, прочитав ее
\texttt{\href{https://www.designofapproxalgs.com/book.pdf}{\underline{здесь}}} 
("1.4 Rounding a dual solution")
}

Задачи линейного программирования можно записывать в матричном виде. Вспомним нашу ослабленную ЛП-задачу:
$$ \summ[m]{j=1} w_j x_j \rightarrow \min,$$
$$ \summ{j:\, e_i \in S_j} x_j \geq 1, \;\;\; i=1..n,$$
$$ x_j \geq 0 \;\;\; j=1..m$$
Положим $w = (w_1, ..., w_m)^T$ -- столбец весов, тогда, очевидно, первое условие переписывается как: $$w^Tx \rightarrow \min$$

Со вторым условием разберемся так. Введем матрицу $\mathcal E$ размера $n \times m$:
$$
\mathcal{E}_{ij} = \begin{cases}
1, & \text{если } e_i \in S_j \\
0, & \text{иначе}
\end{cases}
$$
Тогда для фиксированного $1\leq i \leq n$ условие $\summ{j: e_i \in S_j} x_j \geq 1$ переписывается как $\mathcal{E}_{i*} x \geq 1$. Ясно, что все такие $n$ условий можно заменить одним матричным: $$\mathcal{E}\,x \geq \mathbb I_n,$$ где за $\mathbb I_n$ обозначен столбец из единиц высоты $n$. 

Наконец, третье условие, очевидно, просто заменяется на $$x \geq \mathbb{O}_m,$$ где за $\mathbb{O}_m$ обозначен столбец из нулей высоты $m$.

Итак, мы получили задачу $w^Tx \rightarrow \min$, $\mathcal{E} x \geq \mathbb{I}_n$, $x \geq \mathbb{O}_m$. 

\statement{Определение.}{Пусть дана ЛП-задача вида $c^Tx\rightarrow\min$ с ограничениями $Ax \geq b$, $x \geq \mathbb{O}$. \textbf{Двойственная} к ней ЛП-задача ставится следующим образом: $b^Ty \rightarrow\max$ при ограничениях $A^Ty \leq c$, $y \geq \mathbb{O}$.}

В обозначениях определения имеем $c = w$, $A = \mathcal E$, $b = \mathbb{I}_n$. Поэтому двойственная к нашей ЛП-задаче такова: 
$$\mathbb{I}_n^Ty \rightarrow \max,$$
$$\mathcal{E}^T y \leq w,$$
$$y \geq \mathbb{O}_m$$

Использование этой двойственной задачи на самом деле приведет нас к алгоритму той же эффективности, но далее в билете она пригодится лучше. 

<<Разворачиваем>> матричные обозначения. Перепишем первое ограничение:
$$(\mathcal{E}^Ty)_i = \summ[n]{j=1}\mathcal{E}^T_{ij}y_j = \summ [n]{j=1}\mathcal{E}_{ji}y_j = \summ[n]{j=1} [e_j \in S_i] y_j = \summ{j:\, e_j \in S_i} y_j, \;\; i=1..m$$
Разверните ЦФ и второе ограничение самостоятельно и убедитесь, что вы получили:
$$\summ[n]{j=1} y_j \rightarrow\max,$$
$$\summ{i: e_i \in S_j} y_i\leq w_j, \; j=1..m,$$
$$y_i \geq 0, \; i=1..n$$

Мы наконец-то готовы к созданию приближенного алгоритма на основе двойственной задачи. 

\statement{Приближенное $f$-оптимальное решение (методом двойственной ЛП-задачи, dual).}{}

Аналогично первому разделу, \underline{считаем, что эту задачу мы решать умеем.} Пусть $y^* = (y_1^*, ..., y_n^*)^T$ -- оптимальное решение двойственной ЛП-задачи. Сконструируем из нее решение $I'$ исходной задачи (и задачи Set Cover) следующим образом:
$$j \in I' \iff \summ{i:\, e_i \in S_j}y_i^* = w_j,$$
т.е. берем только те $S_j$, для которых первое ограничение ЛП-задачи обращается в равенство.
Описание алгоритма закончено.

\underline{Найденный набор S-ок действительно покрывает все $E$}.

Действительно, пусть какое-то $e_k$ оказалось не покрытым. Тогда в $I'$ не взяты все $j$ такие, что $S_j$ содержит $e_k$, т.е. для всех $S_j \ni e_k$ справедливо $$\summ{i:\, e_i \in S_j}y_i^* < w_j.$$ 
Обозначим $\e = \minn{j:\, e_k \in S_j} (w_j - \summ{i:\, e_i \in S_j}y_i^*) > 0$. Определим столбец $y'$ следующим образом: $y_k' = y_k^* + \e$, а все остальные $y_j' = y_j^*$. Покажем, что это решение подходит в нашу ЛП-задачу. 

1) Для всякого $S_j \ni e_k$ имеем $\summ{i: e_i \in S_j} y_i' = \e + \summ{i: e_i \in S_j} y_i^* \overset{\text{def }\e}{\leq} (w_j - \summ{i:\, e_i \in S_j}y_i^*) + \summ{i:\, e_i \in S_j}y_i^* = w_j$

2) А для всякого $S_j \not\ni e_k$ имеем просто $\summ{i: e_i \in S_j} y_i' = \summ{i: e_i \in S_j} y_i^* \leq w_j$. 

Таким образом, проверено первое ограничение задачи. Второе ограничение $y_i \geq 0$ тривиально, тем самым, $y'$ -- решение ЛП-задачи. При этом решении значение ЦФ оказывается лучшим, чем при $y^*$: $\summ[n]{j=1}y_j' = \e + \summ[n]{j=1} y_j^* > \summ[n]{j=1} y_j^*$, но мы предполагали, что $y^*$ -- оптимальное решение. Противоречие. 

\underline{Теперь докажем $f$-оптимальность.}
Распишем суммарный вес найденного набора $I'$:
$$\summ{j\in I'} w_j = \summ{j\in I'} \; \summ{i: e_i \in S_j} y_i^* = \summ[m]{j=1}\summ[n]{i=1} [j \in I'] [e_i \in S_j] y_i^* = \summ[n]{i=1}|\{j \in I': e_i \in S_j\}|\cdot y_i^*$$

Оценим сверху в терминах $f_i = |\{j: e_i \in S_j\}|$ и $f = \maxx{i=1..n} f_i$:
$$ \leq \summ[n]{i=1}f_iy_i^* \leq f\summ[n]{i=1} y_i^*$$
Последняя сумма равна оптимальному значению ЦФ двойственной задачи. Воспользуемся без доказательства следующим фактом:

\statement{Теорема (о сильной двойственности).}{Рассмотрим ЛП-задачу и двойственную к ней. Если хотя бы у одной из двух задач есть оптимальное решение, то оно есть и у второй задачи, причем оптимальные значения целевых функций совпадают.} 

Значит, $\summ[n]{i=1} y_i^*$, будучи равной оптимальному значению прямой ЛП-задачи, не превосходит $OPT$. Таким образом, $$\summ{j\in I'} w_j \leq f\cdot OPT \; \blacksquare$$

\subsection{Прямо-двойственный метод}

Алгоритмы, которые решают задачи ЛП, довольно быстры. Но мы хотим еще быстрее.

\statement{Приближенное $f$-оптимальное решение (прямо-двойственный метод, primal-dual).}{}

Вспомним, как мы из решения двойственной ЛП-задачи построили приближенное решение исходной, и \underline{как мы доказали}, что это решение. Идея доказательства -- если данное $I$ не покрытие, то можем увеличить переменную, отвечающую за непокрытый элемент, -- порождает следующий алгоритм:

\begin{lstlisting}[escapeinside=``]
function PrimalDual (`$E = \{e_1, ..., e_n\}$`, `$S_1, ..., S_m$`):
`$y$` `$=$` [0] * n
I `$=$` []
while `$\exists e_i \notin \underset{j\in I}{\bigcup} S_j$`:
    `$l =$` all indices such that `$e_i \in S_l$` and `$\e = (w_l - \summ{k: e_k \in S_l}y_k)$` is minimal
    `$y_i$` += `$\e$`
    I.append(`$l$`)
\end{lstlisting}

Итераций внешнего цикла \textbf{while} не более $n$ штук, так как каждый раз в I добавляем не менее одного элемента. Ясно (из раздела про двойственную задачу), что это корректный $f$-оптимальный алгоритм. $\blacksquare$