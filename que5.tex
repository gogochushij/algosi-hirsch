\hypertarget{setcover}{\section{(5) Set Cover~-- i (Осипов Д.)}}

%куча опечаток, у себя пометил, щас буду исправлять

\begin{problem*}[о покрытии множествами, Set Cover]
	Пусть дано множество $\{e_1, \ldots, e_n\} = E$ и несколько подмножеств $S_1, \ldots, S_m \subseteq E$, каждому $S_j$ присвоен неотрицательный вес $w_j$. Необходимо выбрать из $S_1, \ldots, S_m$ набор, полностью покрывающий $E$, с минимальным суммарным весом. Более формально: требуется найти такое $I \subseteq \{1, \ldots, m\}$, что: $$\bigcup_{j\in I} = E \text{ и } \sum_{j \in I} w_j \text{ минимально.}$$
\end{problem*}

В этом билете представляются различные подходы к приближенным решениям этой задачи.

\subsection{Сведение к задаче линейного программирования}

\begin{definition*}
	{\bfseries Задача линейного программирования}~-- задача минимизации (максимизации) некоторой линейной функции $h = h(x_1, \ldots, x_n)$ при ограничениях вида $g_k \land b_k$, где $\land$ есть один из знаков $\leq, \geq$, а $g_k = g_k(x_1, \ldots, x_n)$~-- линейные функции; $b_k$~-- числа. Функция $h$ называется \textit{целевой} функцией.
\end{definition*}

Далее в тексте сокращение \textit{ЛП-задача} будет означать \textit{задача линейного программирования}.

Обозначим за $f_i$ количество множеств среди $S_1, \ldots, S_m$, в которые входит элемент $e_i$ ($f_i = \left|\{j: e_i \in S_j\}\right|$. Положим $f = \max\limits_{i=1\ldots n} f_i$. Оказывается, что эти параметры играют решающую роль в следующем решении.

Переформулируем задачу Set Cover. Каждому множеству $S_j$ сопоставим переменную $x_j$, принимающую значение 1, если $S_j$ взято в набор ($j \in I$), и 0~-- иначе. Столбец $x = (x_1, \ldots, x_m)^T$ взаимно однозначно кодирует любой набор индексов $I$. Тогда целевая функция~-- суммарный вес покрытия~-- выглядит как $\sum\limits_{j=1}^m w_j x_j$. Ограничение на то, что набор $I$ задает покрытие, записывается так: каждый элемент $e_i$ покрыт хотя бы одним элементом $I$, или же что условие $\sum\limits_{j:\, e_i \in S_j} x_j \geq 1$ выполнено для всех $i=1\ldots n$. Итак, формулировка задачи:

$$\sum_{j=1}^m w_j x_j \rightarrow \min,$$
$$\sum_{j:\, e_i \in S_j} x_j \geq 1, \;\;\; i=1\ldots n,$$
$$x_j \in \{0, 1\}, \;\;\; j=1\ldots m$$

Это \underline{почти} ЛП-задача. Если бы умели решать такие задачи точно, решили бы и нашу~-- это просто ее переформулировка. <<Ослабим>> задачу до настоящей ЛП-задачи:

$$\sum_{j=1}^m w_j x_j \rightarrow \min,$$
$$\sum_{j:\, e_i \in S_j} x_j \geq 1, \;\;\; i=1\ldots n,$$
$$x_j \geq 0 \;\;\; j=1\ldots m$$

Мы перестали требовать, что $x_j$ обязательно должен быть целым и не превышать единицы. Отметим, что если обозначить минимум ЦФ в исходной задаче за $OPT$, а в ослабленной~-- за $Z^*$, то будет справедлива оценка $$Z^* \leq OPT,$$ так как фактически вторая задача~-- следствие первой.

\begin{algodescription}{Приближенное $f$-оптимальное решение (методом прямой ЛП-задачи, primal)}

\underline{Считаем, что ослабленную ЛП-задачу мы решать умеем.} Пусть $x^* = (x_1^*, \ldots, x_m^*)^T$~-- оптимальное решение ослабленной ЛП-задачи, т.е. $Z^* = \sum\limits_{j=1}^m w_j x_j^*$. Сконструируем из нее решение исходной задачи (и задачи Set Cover) следующим образом:
$$x_j = 1\, (j \in I) \iff x_j^* \geq 1/f;$$

Итак, алгоритм заключается в следующем: мы находим точку минимума~-- $x_j^*$~-- ослабленной ЛП-задачи, а далее в покрытие берем все $S_j$, для которых получилось $x_j^* \geq 1/f$.
\end{algodescription}

Теперь докажем его корректность и точность.

\begin{theorem*}
    Найденный набор $S$-ок действительно покрывает всё $E$.
\end{theorem*}
\begin{proof}
    Именно, докажем, что каждый элемент $e_i \in E$ покрыт какой-то $S$-кой. Найденное решение $x^*$ удовлетворяет ослабленной ЛП-задаче, то есть для данного $e_i$ имеем $\sum\limits_{j: \, e_i \in S_j} x_j^* \geq 1$. В этой сумме по определению $f_i = \left|\{j: \, e_i \in S_j\}\right| \leq f$ членов, значит, хотя бы один из них $x_k^*\geq 1/f$. Значит, соответствующий $x_k = 1$, что доказывает то, что $e_i$ покрыт $S_k$.
\end{proof}

\begin{theorem*}
    Приведенный алгоритм $f$-оптимальный.
\end{theorem*}
\begin{proof}
    Обозначим (снова) минимальное значение целевой функции исходной почти-ЛП задачи за $OPT$, а ослабленной ЛП-задачи за $Z \leq OPT$.  (То есть, в обозначениях $x^*$ имеем $Z = \sum\limits_{j=1}^m w_j x_j^*$). Для всякого $j\in I$ имеем $x_j^* \geq 1/f$, или же $x_j^*\cdot f \geq 1$. Тогда значение целевой функции в найденном решении исходной почти-ЛП задачи оценивается как:
    $$\sum_{j=1}^m w_j x_j = \sum_{j \in I} w_j \leq f \sum_{j \in I} w_j x_j^* \leq f \sum_{j=1}^m w_j x_j^* = f Z^* \leq f \cdot OPT.$$ Таким образом, найденное решение хуже оптимального не более, чем в $f$ раз.
\end{proof}

\subsection{Следствие для задачи вершинного покрытия (Vertex Cover)}
\begin{problem*}[о вершинном покрытии, Vertex Cover]
	Пусть дан неориентированный граф $G = (V, E)$, каждой вершине $i$ которого сопоставлен неотрицательный вес $w_i$. Найти минимальный по весу набор вершин $C \subseteq V$ такой, что всякое ребро графа хотя бы одним из двух концов лежит в $C$.
\end{problem*}
\begin{algodescription}{Приближенное 2-оптимальное решение} Это частный случай задачи Set Cover: основное множество~-- множество ребер графа $E$, а каждой вершине $i \in V$ сопоставляется множество $S_i$ веса $w_i$, состоящее из ребер, смежных с $i$. Причем в обозначениях предыдущего раздела каждое ребро $(i, j)$ содержится ровно в двух множествах: $S_i, S_j$, поэтому $f = 2$, а значит, алгоритм становится 2-оптимальным.
\end{algodescription}

\subsection{Двойственная задача}
\texttt{От автора: к сожалению, получился не очень приятный для чтения параграф. Автор не смог вникнуть в <<экономический смысл>> двойственной ЛП-задачи, поэтому все рассуждения построены на противной формалистике с матрицами и суммами. Возможно, вы лучше поймете эту тему, прочитав ее
\texttt{\href{https://www.designofapproxalgs.com/book.pdf}{\underline{здесь}}}
("1.4 Rounding a dual solution")
}

Задачи линейного программирования можно записывать в матричном виде. Вспомним нашу ослабленную ЛП-задачу:
$$ \sum_{j=1}^m w_j x_j \rightarrow \min,$$
$$ \sum_{j:\, e_i \in S_j} x_j \geq 1, \;\;\; i=1\ldots n,$$
$$ x_j \geq 0 \;\;\; j=1\ldots m$$
Положим $w = (w_1, \ldots, w_m)^T$~-- столбец весов, тогда, очевидно, первое условие переписывается как: $$w^Tx \rightarrow \min$$

Со вторым условием разберемся так. Введем матрицу $\mathcal E$ размера $n \times m$:
$$
\mathcal{E}_{ij} = \begin{cases}
1, & \text{если } e_i \in S_j \\
0, & \text{иначе}
\end{cases}
$$

Тогда для фиксированного $1\leq i \leq n$ условие $\sum\limits_{j: e_i \in S_j} x_j \geq 1$ переписывается как $\mathcal{E}_{i*} x \geq 1$. Ясно, что все такие $n$ условий можно заменить одним матричным: $$\mathcal{E}\,x \geq \mathbb I_n,$$ где за $\mathbb I_n$ обозначен столбец из единиц высоты $n$. Отношение $\geq$, естественно, поэлементное.

Наконец, третье условие, очевидно, просто заменяется на $$x \geq \mathbb{O}_m,$$ где за $\mathbb{O}_m$ обозначен столбец из нулей высоты $m$.

Итак, мы получили задачу $$w^Tx \rightarrow \min, \; \mathcal{E} x \geq \mathbb{I}_n, \; x \geq \mathbb{O}_m.$$

\begin{definition*}
	Пусть дана ЛП-задача вида $$c^Tx\rightarrow\min, \; Ax \geq b, \; x \geq \mathbb{O}.$$ \textbf{Двойственная} к ней ЛП-задача ставится следующим образом: $$b^Ty \rightarrow\max, \;  A^Ty \leq c, \; y \geq \mathbb{O}.$$
\end{definition*}

Мы поверим в следующий факт.

\begin{theorem*}[о сильной двойственности]
	Рассмотрим ЛП-задачу и двойственную к ней. Если хотя бы у одной из двух задач есть оптимальное решение, то оно есть и у второй задачи, причем оптимальные значения целевых функций совпадают.
\end{theorem*}

В обозначениях определения имеем $c = w$, $A = \mathcal E$, $b = \mathbb{I}_n$. Поэтому двойственная к нашей ЛП-задаче такова:
$$\mathbb{I}_n^Ty \rightarrow \max, \; \mathcal{E}^T y \leq w, \; y \geq \mathbb{O}_m$$

Использование этой двойственной задачи на самом деле приведет нас к алгоритму той же эффективности, но далее в билете она пригодится лучше.

<<Разворачиваем>> матричные обозначения. Перепишем первое ограничение:
$$(\mathcal{E}^Ty)_i = \sum_{j=1}^n\mathcal{E}^T_{ij}y_j = \sum_{j=1}^n\mathcal{E}_{ji}y_j = \sum_{j=1}^n [e_j \in S_i] y_j = \sum_{j:\, e_j \in S_i} y_j, \;\; i=1\ldots m$$
Разверните ЦФ и второе ограничение самостоятельно и убедитесь, что вы получили:
$$\sum_{j=1}^n y_j \rightarrow\max,$$
$$\sum_{i: e_i \in S_j} y_i\leq w_j, \; j=1\ldots m,$$
$$y_i \geq 0, \; i=1\ldots n$$

Мы наконец-то готовы к созданию приближенного алгоритма на основе двойственной задачи.

\begin{algodescription}{Приближенное $f$-оптимальное решение (методом двойственной ЛП-задачи, dual)}
    Аналогично первому разделу, \underline{считаем, что эту задачу мы решать умеем.} Пусть $y^* = (y_1^*, \ldots, y_n^*)^T$~-- оптимальное решение двойственной ЛП-задачи. Сконструируем из нее решение $I'$ исходной задачи (и задачи Set Cover) следующим образом:
    $$j \in I' \iff \sum_{i:\, e_i \in S_j}y_i^* = w_j,$$
    т.е. берем только те $S_j$, для которых первое ограничение ЛП-задачи обращается в равенство.
\end{algodescription}

\begin{theorem*}
    Найденный набор S-ок действительно покрывает все $E$.
\end{theorem*}
\begin{proof}
    Действительно, пусть какое-то $e_k$ оказалось не покрытым. Тогда в $I'$ не взяты все $j$ такие, что $S_j$ содержит $e_k$, т.е. для всех $S_j \ni e_k$ справедливо $$\sum_{i:\, e_i \in S_j}y_i^* < w_j.$$
    Обозначим $\e = \min\limits_{j:\, e_k \in S_j} \left(w_j - \sum\limits_{i:\, e_i \in S_j}y_i^*\right) > 0$. Определим столбец $y'$ следующим образом: $y_k' = y_k^* + \e$, а все остальные $y_j' = y_j^*$. Покажем, что это решение подходит в нашу ЛП-задачу.
    \begin{enumerate}
        \item Для всякого $S_j \ni e_k$ имеем $\sum\limits_{i: e_i \in S_j} y_i' = \e + \sum\limits_{i: e_i \in S_j} y_i^* \overset{\text{def }\e}{\leq} \left(w_j - \sum\limits_{i:\, e_i \in S_j}y_i^*\right) + \sum\limits_{i:\, e_i \in S_j}y_i^* = w_j$

        \item А для всякого $S_j \not\ni e_k$ имеем просто $\sum\limits_{i: e_i \in S_j} y_i' = \sum\limits_{i: e_i \in S_j} y_i^* \leq w_j$.
    \end{enumerate}

    Таким образом, проверено первое ограничение задачи. Второе ограничение $y_i \geq 0$ тривиально, тем самым, $y'$~-- решение ЛП-задачи. При этом решении значение ЦФ оказывается лучшим, чем при $y^*$: $\sum\limits_{j=1}^ny_j' = \e + \sum\limits_{j=1}^n y_j^* > \sum\limits_{j=1}^n y_j^*$, но мы предполагали, что $y^*$~-- оптимальное решение. Противоречие.
\end{proof}

\begin{theorem*}
    Приведенный алгоритм $f$-оптимален.
\end{theorem*}
\begin{proof}
    Распишем суммарный вес найденного набора $I'$:
	$$\sum_{j\in I'} w_j = \sum_{j\in I'} \; \sum_{i: e_i \in S_j} y_i^* = \sum_{j=1}^m\sum_{i=1}^n [j \in I'] [e_i \in S_j] y_i^* = \sum_{j=1}^m \sum_{i=1}^n\left|\{j \in I': e_i \in S_j\}\right|\cdot y_i^*$$

    Оценим сверху в терминах $f_i = \left|\{j: e_i \in S_j\}\right|$ и $f = \max\limits_{i=1\ldots n} f_i$:
    $$ \leq \sum_{i=1}^nf_iy_i^* \leq f\sum_{i=1}^n y_i^*$$
    Последняя сумма равна оптимальному значению ЦФ двойственной задачи. Из теоремы о сильной двойственности следует, что $\sum\limits_{i=1}^n y_i^*$, будучи равной оптимальному значению прямой ЛП-задачи, не превосходит $OPT$. Таким образом, $$\sum_{j\in I'} w_j \leq f\cdot OPT$$
\end{proof}

\subsection{Прямо-двойственный метод}

Алгоритмы, которые решают задачи ЛП, довольно быстры. Но мы хотим еще быстрее.

\begin{algodescription}{Приближенное $f$-оптимальное решение (прямо-двойственный метод, primal-dual)}
    Вспомним, как мы из решения двойственной ЛП-задачи построили приближенное решение исходной, и \underline{как мы доказали}, что это решение. Идея доказательства~-- если данное $I$ не задает покрытие, то можем увеличить переменную, отвечающую за непокрытый элемент,~-- порождает следующий алгоритм.

    Положим $y$~-- нулевой столбец, в этом $y$ будем строить решение двойственной задачи. Именно, пока существует непокрытый $e_i$, мы можем увеличить $y_i$ на величину $\e$, таким образом не нарушив ограничения ЛП-задачи. Ну и будем так действовать, пока не покроем все $e_i$.

    \begin{algorithm}
    	\DontPrintSemicolon
    	\SetKwFor{While}{while}{:}{}
    	\SetKwProg{Fn}{}{:}{}
    	\SetKwFunction{PrimalDual}{PrimalDual}
    	\SetKw{add}{Добавить}
    	\Fn{\PrimalDual{$E=\{e_1,\ldots,e_n\}, S_1,\ldots,S_m$}}{
    		$y$ = $[0] * n$\;
    		I = $[]$\;
    		\While{$\exists e_i \notin \bigcup\limits_{j\in I} S_j$}{
    			$l$ = тот индекс (возможно, несколько), для которого $e_i \in S_l$ \textbf{и} $\e = \left(w_l-\sum\limits_{k:e_k\in S_l} y_k\right)$ \textbf{минимален}\;
    			$y_i$ += $\e$\;
				\add $l$ в I (если несколько, то добавить все)\;
    		}
    	}
    \end{algorithm}

    Итераций внешнего цикла \textbf{while} не более $n$ штук, так как каждый раз в I добавляем не менее одного элемента. Ясно (из раздела про двойственную задачу), что это корректный $f$-оптимальный алгоритм.
\end{algodescription}
